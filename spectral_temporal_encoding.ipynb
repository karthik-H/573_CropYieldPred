{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os3Vwwijh4hU",
        "outputId": "4ac0741b-64bf-44d9-c583-c705c4dde535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchnet in ./.project/lib/python3.10/site-packages (0.0.4)\n",
            "Requirement already satisfied: torch in ./.project/lib/python3.10/site-packages (2.3.0)\n",
            "Requirement already satisfied: numpy in ./.project/lib/python3.10/site-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in ./.project/lib/python3.10/site-packages (2.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-macosx_12_0_arm64.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in ./.project/lib/python3.10/site-packages (from torchnet) (1.16.0)\n",
            "Requirement already satisfied: visdom in ./.project/lib/python3.10/site-packages (from torchnet) (0.2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./.project/lib/python3.10/site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: networkx in ./.project/lib/python3.10/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: sympy in ./.project/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: filelock in ./.project/lib/python3.10/site-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: jinja2 in ./.project/lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in ./.project/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.project/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.project/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.project/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.project/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
            "Collecting joblib>=1.2.0\n",
            "  Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.2/301.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.project/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.project/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: requests in ./.project/lib/python3.10/site-packages (from visdom->torchnet) (2.31.0)\n",
            "Requirement already satisfied: tornado in ./.project/lib/python3.10/site-packages (from visdom->torchnet) (6.4)\n",
            "Requirement already satisfied: jsonpatch in ./.project/lib/python3.10/site-packages (from visdom->torchnet) (1.33)\n",
            "Requirement already satisfied: websocket-client in ./.project/lib/python3.10/site-packages (from visdom->torchnet) (1.8.0)\n",
            "Requirement already satisfied: pillow in ./.project/lib/python3.10/site-packages (from visdom->torchnet) (10.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./.project/lib/python3.10/site-packages (from jsonpatch->visdom->torchnet) (2.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.project/lib/python3.10/site-packages (from requests->visdom->torchnet) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.project/lib/python3.10/site-packages (from requests->visdom->torchnet) (2024.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.project/lib/python3.10/site-packages (from requests->visdom->torchnet) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.project/lib/python3.10/site-packages (from requests->visdom->torchnet) (3.7)\n",
            "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
            "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 threadpoolctl-3.5.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torchnet torch numpy pandas scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a2Iu7FuOhJV8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import pickle as pkl\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import KFold\n",
        "from dataset import PixelSetData_preloaded\n",
        "# class PixelSetData(data.Dataset):\n",
        "#     def __init__(self, folder, labels, npixel, sub_classes=None, norm=None,\n",
        "#                  extra_feature=None, jitter=(0.01, 0.05), return_id=False):\n",
        "#         \"\"\"\n",
        "\n",
        "#         Args:\n",
        "#             folder (str): path to the main folder of the dataset, formatted as indicated in the readme\n",
        "#             labels (str): name of the nomenclature to use in the labels.json file\n",
        "#             npixel (int): Number of sampled pixels in each parcel\n",
        "#             sub_classes (list): If provided, only the samples from the given list of classes are considered.\n",
        "#             (Can be used to remove classes with too few samples)\n",
        "#             norm (tuple): (mean,std) tuple to use for normalization\n",
        "#             extra_feature (str): name of the additional static feature file to use\n",
        "#             jitter (tuple): if provided (sigma, clip) values for the addition random gaussian noise\n",
        "#             return_id (bool): if True, the id of the yielded item is also returned (useful for inference)\n",
        "#         \"\"\"\n",
        "#         super(PixelSetData, self).__init__()\n",
        "\n",
        "#         self.folder = folder\n",
        "#         self.data_folder = os.path.join(folder, 'DATA')\n",
        "#         self.meta_folder = os.path.join(folder, 'META')\n",
        "#         self.labels = labels\n",
        "#         self.npixel = npixel\n",
        "#         self.norm = norm\n",
        "\n",
        "#         self.extra_feature = extra_feature\n",
        "#         self.jitter = jitter  # (sigma , clip )\n",
        "#         self.return_id = return_id\n",
        "\n",
        "#         l = [f for f in os.listdir(self.data_folder) if f.endswith('.npy')]\n",
        "#         self.pid = [int(f.split('.')[0]) for f in l]\n",
        "#         self.pid = list(np.sort(self.pid))\n",
        "\n",
        "#         self.pid = list(map(str, self.pid))\n",
        "#         self.len = len(self.pid)\n",
        "\n",
        "#         # Get Labels\n",
        "#         if sub_classes is not None:\n",
        "#           sub_indices = []\n",
        "#           num_classes = len(sub_classes)\n",
        "#           convert = dict((c, i) for i, c in enumerate(sub_classes))\n",
        "#           with open(os.path.join(folder, 'META', 'labels.json'), 'r') as file:\n",
        "#             d = json.loads(file.read())\n",
        "#             self.target = []\n",
        "#             for i, p in enumerate(self.pid):\n",
        "#               t = d[labels][p]\n",
        "#               self.target.append(t)\n",
        "#               if sub_classes is not None:\n",
        "#                 if t in sub_classes:\n",
        "#                   sub_indices.append(i)\n",
        "#                   self.target[-1] = convert[self.target[-1]]\n",
        "#         else:\n",
        "#           self.target = []\n",
        "\n",
        "#         if sub_classes is not None:\n",
        "#             self.pid = list(np.array(self.pid)[sub_indices])\n",
        "#             self.target = list(np.array(self.target)[sub_indices])\n",
        "#             self.len = len(sub_indices)\n",
        "\n",
        "#         with open(os.path.join(folder, 'META', 'dates.json'), 'r') as file:\n",
        "#             d = json.loads(file.read())\n",
        "#         self.dates = [d[str(i)] for i in range(len(d))]\n",
        "#         self.date_positions = date_positions(self.dates)\n",
        "\n",
        "#         if self.extra_feature is not None:\n",
        "#             with open(os.path.join(self.meta_folder, '{}.json'.format(extra_feature)), 'r') as file:\n",
        "#                 self.extra = json.loads(file.read())\n",
        "\n",
        "#             if isinstance(self.extra[list(self.extra.keys())[0]], int):\n",
        "#                 for k in self.extra.keys():\n",
        "#                     self.extra[k] = [self.extra[k]]\n",
        "#             df = pd.DataFrame(self.extra).transpose()\n",
        "#             self.extra_m, self.extra_s = np.array(df.mean(axis=0)), np.array(df.std(axis=0))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.len\n",
        "\n",
        "#     def __getitem__(self, item):\n",
        "#         \"\"\"\n",
        "#         Returns a Pixel-Set sequence tensor with its pixel mask and optional additional features.\n",
        "#         For each item npixel pixels are randomly dranw from the available pixels.\n",
        "#         If the total number of pixel is too small one arbitrary pixel is repeated. The pixel mask keeps track of true\n",
        "#         and repeated pixels.\n",
        "#         Returns:\n",
        "#               (Pixel-Set, Pixel-Mask) or ((Pixel-Set, Pixel-Mask), Extra-features) with:\n",
        "#                 Pixel-Set: Sequence_length x Channels x npixel\n",
        "#                 Pixel-Mask : Sequence_length x npixel\n",
        "#                 Extra-features : Sequence_length x Number of additional features\n",
        "\n",
        "#         \"\"\"\n",
        "#         x0 = np.load(os.path.join(self.folder, 'DATA', '{}.npy'.format(self.pid[item])))\n",
        "#         if len(self.target) > 0:\n",
        "#           y = self.target[item]\n",
        "#         else:\n",
        "#           y = 1\n",
        "\n",
        "#         if x0.shape[-1] > self.npixel:\n",
        "#             idx = np.random.choice(list(range(x0.shape[-1])), size=self.npixel, replace=False)\n",
        "#             x = x0[:, :, idx]\n",
        "#             mask = np.ones(self.npixel)\n",
        "\n",
        "#         elif x0.shape[-1] < self.npixel:\n",
        "\n",
        "#             if x0.shape[-1] == 0:\n",
        "#                 x = np.zeros((*x0.shape[:2], self.npixel))\n",
        "#                 mask = np.zeros(self.npixel)\n",
        "#                 mask[0] = 1\n",
        "#             else:\n",
        "#                 x = np.zeros((*x0.shape[:2], self.npixel))\n",
        "#                 x[:, :, :x0.shape[-1]] = x0\n",
        "#                 x[:, :, x0.shape[-1]:] = np.stack([x[:, :, 0] for _ in range(x0.shape[-1], x.shape[-1])], axis=-1)\n",
        "#                 mask = np.array(\n",
        "#                     [1 for _ in range(x0.shape[-1])] + [0 for _ in range(x0.shape[-1], self.npixel)])\n",
        "#         else:\n",
        "#             x = x0\n",
        "#             mask = np.ones(self.npixel)\n",
        "\n",
        "#         if self.norm is not None:\n",
        "#             m, s = self.norm\n",
        "#             m = np.array(m)\n",
        "#             s = np.array(s)\n",
        "\n",
        "#             if len(m.shape) == 0:\n",
        "#                 x = (x - m) / s\n",
        "#             elif len(m.shape) == 1:  # Normalise channel-wise\n",
        "#                 x = (x.swapaxes(1, 2) - m) / s\n",
        "#                 x = x.swapaxes(1, 2)  # Normalise channel-wise for each date\n",
        "#             elif len(m.shape) == 2:\n",
        "#                 x = np.rollaxis(x, 2)  # TxCxS -> SxTxC\n",
        "#                 x = (x - m) / s\n",
        "#                 x = np.swapaxes((np.rollaxis(x, 1)), 1, 2)\n",
        "#         x = x.astype('float')\n",
        "\n",
        "#         if self.jitter is not None:\n",
        "#             sigma, clip = self.jitter\n",
        "#             x = x + np.clip(sigma * np.random.randn(*x.shape), -1 * clip, clip)\n",
        "\n",
        "#         mask = np.stack([mask for _ in range(x.shape[0])], axis=0)  # Add temporal dimension to mask\n",
        "#         data = (Tensor(x), Tensor(mask))\n",
        "\n",
        "#         if self.extra_feature is not None:\n",
        "#             ef = (self.extra[str(self.pid[item])] - self.extra_m) / self.extra_s\n",
        "#             ef = torch.from_numpy(ef).float()\n",
        "\n",
        "#             ef = torch.stack([ef for _ in range(data[0].shape[0])], dim=0)\n",
        "#             data = (data, ef)\n",
        "\n",
        "#         if self.return_id:\n",
        "#             return data, torch.from_numpy(np.array(y, dtype=int)), self.pid[item]\n",
        "#         else:\n",
        "#             return data, torch.from_numpy(np.array(y, dtype=int))\n",
        "\n",
        "\n",
        "# class PixelSetData_preloaded(PixelSetData):\n",
        "#     \"\"\" Wrapper class to load all the dataset to RAM at initialization (when the hardware permits it).\n",
        "#     \"\"\"\n",
        "\n",
        "#     def __init__(self, folder, labels, npixel, sub_classes=None, norm=None,\n",
        "#                  extra_feature=None, jitter=(0.01, 0.05), return_id=False):\n",
        "#         super(PixelSetData_preloaded, self).__init__(folder, labels, npixel, sub_classes=sub_classes, norm=norm,\n",
        "#                  extra_feature=extra_feature, jitter=jitter, return_id=return_id)\n",
        "#         self.samples = []\n",
        "#         print('Loading samples to memory . . .')\n",
        "#         for item in range(len(self)):\n",
        "#             self.samples.append(super(PixelSetData_preloaded, self).__getitem__(item))\n",
        "#         print('Done !')\n",
        "\n",
        "#     def __getitem__(self, item):\n",
        "#         return self.samples[item]\n",
        "\n",
        "\n",
        "# def parse(date):\n",
        "#     d = str(date)\n",
        "#     return int(d[:4]), int(d[4:6]), int(d[6:])\n",
        "\n",
        "\n",
        "# def interval_days(date1, date2):\n",
        "#     return abs((dt.datetime(*parse(date1)) - dt.datetime(*parse(date2))).days)\n",
        "\n",
        "\n",
        "# def date_positions(dates):\n",
        "#     pos = []\n",
        "#     for d in dates:\n",
        "#         pos.append(interval_days(d, dates[0]))\n",
        "#     return pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02S6cw8zYxaZ",
        "outputId": "40cf3b37-5798-4dd6-ab1f-a832fa918abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading samples to memory . . .\n",
            "Done !\n"
          ]
        }
      ],
      "source": [
        "subset = [1, 3, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18, 19, 23, 28, 31, 33, 34, 36, 39]\n",
        "# mean_std = pkl.load(open('./PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "# dt1 = PixelSetData_preloaded('./PixelSet-TOY/', labels='label_44class', npixel=64,\n",
        "#                                     sub_classes=subset,\n",
        "#                                     norm=mean_std,\n",
        "#                                     extra_feature=None)\n",
        "mean_std = pkl.load(open('./pixelset_train/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "dt1 = PixelSetData_preloaded('./pixelset_train/', labels='label_19class', npixel=64,\n",
        "                                    sub_classes=None,\n",
        "                                    norm=mean_std,\n",
        "                                    extra_feature=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbaH4PpLdabd",
        "outputId": "0386c8bd-7dff-4e29-e151-824dedbc8ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading samples to memory . . .\n",
            "Done !\n"
          ]
        }
      ],
      "source": [
        "# subset = [1, 3, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18, 19, 23, 28, 31, 33, 34, 36, 39]\n",
        "# mean_std = pkl.load(open('./PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "# dttest = PixelSetData_preloaded('./test/', labels='label_19class', npixel=64,\n",
        "#                                     sub_classes=None,\n",
        "#                                     norm=mean_std,\n",
        "#                                     extra_feature=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iyoe4Nn2Zlsi"
      },
      "outputs": [],
      "source": [
        "def get_loaders(dt, kfold):\n",
        "    indices = list(range(len(dt)))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    kf = KFold(n_splits=kfold, shuffle=False)\n",
        "    indices_seq = list(kf.split(list(range(len(dt)))))\n",
        "    ntest = len(indices_seq[0][1])\n",
        "\n",
        "    loader_seq = []\n",
        "    for trainval, test_indices in indices_seq:\n",
        "        trainval = [indices[i] for i in trainval]\n",
        "        test_indices = [indices[i] for i in test_indices]\n",
        "\n",
        "        validation_indices = trainval[-ntest:]\n",
        "        train_indices = trainval[:-ntest]\n",
        "\n",
        "        train_sampler = data.sampler.SubsetRandomSampler(train_indices)\n",
        "        validation_sampler = data.sampler.SubsetRandomSampler(validation_indices)\n",
        "        test_sampler = data.sampler.SubsetRandomSampler(test_indices)\n",
        "\n",
        "        train_loader = data.DataLoader(dt, batch_size=128,\n",
        "                                       sampler=train_sampler,\n",
        "                                       num_workers=8)\n",
        "        validation_loader = data.DataLoader(dt, batch_size=128,\n",
        "                                            sampler=validation_sampler,\n",
        "                                            num_workers=8)\n",
        "        test_loader = data.DataLoader(dt, batch_size=128,\n",
        "                                      sampler=test_sampler,\n",
        "                                      num_workers=8)\n",
        "\n",
        "        loader_seq.append((train_loader, validation_loader, test_loader))\n",
        "    return loader_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r2mTO6AAiQX3"
      },
      "outputs": [],
      "source": [
        "class PixelSetEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, mlp1=[10, 32, 64], pooling='mean_std', mlp2=[64, 128], with_extra=True,\n",
        "                 extra_size=4):\n",
        "        \"\"\"\n",
        "        Pixel-set encoder.\n",
        "        Args:\n",
        "            input_dim (int): Number of channels of the input tensors\n",
        "            mlp1 (list):  Dimensions of the successive feature spaces of MLP1\n",
        "            pooling (str): Pixel-embedding pooling strategy, can be chosen in ('mean','std','max,'min')\n",
        "                or any underscore-separated combination thereof.\n",
        "            mlp2 (list): Dimensions of the successive feature spaces of MLP2\n",
        "            with_extra (bool): Whether additional pre-computed features are passed between the two MLPs\n",
        "            extra_size (int, optional): Number of channels of the additional features, if any.\n",
        "        \"\"\"\n",
        "\n",
        "        super(PixelSetEncoder, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.mlp1_dim = copy.deepcopy(mlp1)\n",
        "        self.mlp2_dim = copy.deepcopy(mlp2)\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.with_extra = with_extra\n",
        "        self.extra_size = extra_size\n",
        "\n",
        "        self.name = 'PSE-{}-{}-{}'.format('|'.join(list(map(str, self.mlp1_dim))), pooling,\n",
        "                                          '|'.join(list(map(str, self.mlp2_dim))))\n",
        "\n",
        "        self.output_dim = input_dim * len(pooling.split('_')) if len(self.mlp2_dim) == 0 else self.mlp2_dim[-1]\n",
        "\n",
        "        inter_dim = self.mlp1_dim[-1] * len(pooling.split('_'))\n",
        "\n",
        "\n",
        "        if self.with_extra:\n",
        "            self.name += 'Extra'\n",
        "            inter_dim += self.extra_size\n",
        "        print(inter_dim)\n",
        "        print(mlp2[0])\n",
        "        assert (input_dim == mlp1[0])\n",
        "        assert (inter_dim == mlp2[0])\n",
        "        # Feature extraction\n",
        "        layers = []\n",
        "        for i in range(len(self.mlp1_dim) - 1):\n",
        "            layers.append(linlayer(self.mlp1_dim[i], self.mlp1_dim[i + 1]))\n",
        "        self.mlp1 = nn.Sequential(*layers)\n",
        "\n",
        "        # MLP after pooling\n",
        "        layers = []\n",
        "        for i in range(len(self.mlp2_dim) - 1):\n",
        "            layers.append(nn.Linear(self.mlp2_dim[i], self.mlp2_dim[i + 1]))\n",
        "            layers.append(nn.BatchNorm1d(self.mlp2_dim[i + 1]))\n",
        "            if i < len(self.mlp2_dim) - 2:\n",
        "                layers.append(nn.ReLU())\n",
        "        self.mlp2 = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        The input of the PSE is a tuple of tensors as yielded by the PixelSetData class:\n",
        "          (Pixel-Set, Pixel-Mask) or ((Pixel-Set, Pixel-Mask), Extra-features)\n",
        "        Pixel-Set : Batch_size x (Sequence length) x Channel x Number of pixels\n",
        "        Pixel-Mask : Batch_size x (Sequence length) x Number of pixels\n",
        "        Extra-features : Batch_size x (Sequence length) x Number of features\n",
        "\n",
        "        If the input tensors have a temporal dimension, it will be combined with the batch dimension so that the\n",
        "        complete sequences are processed at once. Then the temporal dimension is separated back to produce a tensor of\n",
        "        shape Batch_size x Sequence length x Embedding dimension\n",
        "        \"\"\"\n",
        "        a, b = input\n",
        "        if len(a) == 2:\n",
        "            out, mask = a\n",
        "            extra = b\n",
        "            if len(extra) == 2:\n",
        "                extra, bm = extra\n",
        "        else:\n",
        "            out, mask = a, b\n",
        "\n",
        "        if len(out.shape) == 4:\n",
        "            # Combine batch and temporal dimensions in case of sequential input\n",
        "            reshape_needed = True\n",
        "            batch, temp = out.shape[:2]\n",
        "\n",
        "            out = out.view(batch * temp, *out.shape[2:])\n",
        "            mask = mask.view(batch * temp, -1)\n",
        "            if self.with_extra:\n",
        "                extra = extra.view(batch * temp, -1)\n",
        "        else:\n",
        "            reshape_needed = False\n",
        "\n",
        "        out = self.mlp1(out)\n",
        "        out = torch.cat([pooling_methods[n](out, mask) for n in self.pooling.split('_')], dim=1)\n",
        "\n",
        "        if self.with_extra:\n",
        "            out = torch.cat([out, extra], dim=1)\n",
        "        out = self.mlp2(out)\n",
        "\n",
        "        if reshape_needed:\n",
        "            out = out.view(batch, temp, -1)\n",
        "        return out\n",
        "\n",
        "class linlayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(linlayer, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "\n",
        "        self.lin = nn.Linear(in_dim, out_dim)\n",
        "        self.bn = nn.BatchNorm1d(out_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = input.permute((0, 2, 1))  # to channel last\n",
        "        out = self.lin(out)\n",
        "\n",
        "        out = out.permute((0, 2, 1))  # to channel first\n",
        "        out = self.bn(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "def masked_mean(x, mask):\n",
        "    out = x.permute((1, 0, 2))\n",
        "    out = out * mask\n",
        "    out = out.sum(dim=-1) / mask.sum(dim=-1)\n",
        "    out = out.permute((1, 0))\n",
        "    return out\n",
        "\n",
        "def masked_std(x, mask):\n",
        "    m = masked_mean(x, mask)\n",
        "\n",
        "    out = x.permute((2, 0, 1))\n",
        "    out = out - m\n",
        "    out = out.permute((2, 1, 0))\n",
        "\n",
        "    out = out * mask\n",
        "    d = mask.sum(dim=-1)\n",
        "    d[d == 1] = 2\n",
        "\n",
        "    out = (out ** 2).sum(dim=-1) / (d - 1)\n",
        "    out = torch.sqrt(out + 10e-32) # To ensure differentiability\n",
        "    out = out.permute(1, 0)\n",
        "    return out\n",
        "\n",
        "def maximum(x, mask):\n",
        "    return x.max(dim=-1)[0].squeeze()\n",
        "\n",
        "def minimum(x, mask):\n",
        "    return x.min(dim=-1)[0].squeeze()\n",
        "\n",
        "pooling_methods = {\n",
        "    'mean': masked_mean,\n",
        "    'std': masked_std,\n",
        "    'max': maximum,\n",
        "    'min': minimum\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GJutIM4Viipu"
      },
      "outputs": [],
      "source": [
        "class LTAE(nn.Module):\n",
        "    def __init__(self, in_channels=128, n_head=16, d_k=8, n_neurons=[256,128], dropout=0.2, d_model=256,\n",
        "                 T=1000, len_max_seq=24, positions=None, return_att=False):\n",
        "        \"\"\"\n",
        "        Sequence-to-embedding encoder.\n",
        "        Args:\n",
        "            in_channels (int): Number of channels of the input embeddings\n",
        "            n_head (int): Number of attention heads\n",
        "            d_k (int): Dimension of the key and query vectors\n",
        "            n_neurons (list): Defines the dimensions of the successive feature spaces of the MLP that processes\n",
        "                the concatenated outputs of the attention heads\n",
        "            dropout (float): dropout\n",
        "            T (int): Period to use for the positional encoding\n",
        "            len_max_seq (int, optional): Maximum sequence length, used to pre-compute the positional encoding table\n",
        "            positions (list, optional): List of temporal positions to use instead of position in the sequence\n",
        "            d_model (int, optional): If specified, the input tensors will first processed by a fully connected layer\n",
        "                to project them into a feature space of dimension d_model\n",
        "            return_att (bool): If true, the module returns the attention masks along with the embeddings (default False)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super(LTAE, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.positions = positions\n",
        "        self.n_neurons = copy.deepcopy(n_neurons)\n",
        "        self.return_att = return_att\n",
        "\n",
        "\n",
        "        if positions is None:\n",
        "            positions = len_max_seq + 1\n",
        "\n",
        "        if d_model is not None:\n",
        "            self.d_model = d_model\n",
        "            self.inconv = nn.Sequential(nn.Conv1d(in_channels, d_model, 1),\n",
        "                                        nn.LayerNorm((d_model, len_max_seq)))\n",
        "        else:\n",
        "            self.d_model = in_channels\n",
        "            self.inconv = None\n",
        "\n",
        "        sin_tab = get_sinusoid_encoding_table(positions, self.d_model // n_head, T=T)\n",
        "        self.position_enc = nn.Embedding.from_pretrained(torch.cat([sin_tab for _ in range(n_head)], dim=1),\n",
        "                                                         freeze=True)\n",
        "\n",
        "        self.inlayernorm = nn.LayerNorm(self.in_channels)\n",
        "\n",
        "        self.outlayernorm = nn.LayerNorm(n_neurons[-1])\n",
        "\n",
        "        self.attention_heads = MultiHeadAttention(\n",
        "            n_head=n_head, d_k=d_k, d_in=self.d_model)\n",
        "\n",
        "        assert (self.n_neurons[0] == self.d_model)\n",
        "\n",
        "        activation = nn.ReLU()\n",
        "\n",
        "        layers = []\n",
        "        for i in range(len(self.n_neurons) - 1):\n",
        "            layers.extend([nn.Linear(self.n_neurons[i], self.n_neurons[i + 1]),\n",
        "                           nn.BatchNorm1d(self.n_neurons[i + 1]),\n",
        "                           activation])\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        sz_b, seq_len, d = x.shape\n",
        "\n",
        "        x = self.inlayernorm(x)\n",
        "\n",
        "        if self.inconv is not None:\n",
        "            x = self.inconv(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
        "\n",
        "        if self.positions is None:\n",
        "            src_pos = torch.arange(1, seq_len + 1, dtype=torch.long).expand(sz_b, seq_len).to(x.device)\n",
        "        else:\n",
        "            src_pos = torch.arange(0, seq_len, dtype=torch.long).expand(sz_b, seq_len).to(x.device)\n",
        "        enc_output = x + self.position_enc(src_pos)\n",
        "\n",
        "        enc_output, attn = self.attention_heads(enc_output, enc_output, enc_output)\n",
        "\n",
        "        enc_output = enc_output.permute(1, 0, 2).contiguous().view(sz_b, -1)  # Concatenate heads\n",
        "\n",
        "        enc_output = self.outlayernorm(self.dropout(self.mlp(enc_output)))\n",
        "\n",
        "        if self.return_att:\n",
        "            return enc_output, attn\n",
        "        else:\n",
        "            return enc_output\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' Multi-Head Attention module '''\n",
        "\n",
        "    def __init__(self, n_head, d_k, d_in):\n",
        "        super().__init__()\n",
        "        self.n_head = n_head\n",
        "        self.d_k = d_k\n",
        "        self.d_in = d_in\n",
        "\n",
        "        self.Q = nn.Parameter(torch.zeros((n_head, d_k))).requires_grad_(True)\n",
        "        nn.init.normal_(self.Q, mean=0, std=np.sqrt(2.0 / (d_k)))\n",
        "\n",
        "        self.fc1_k = nn.Linear(d_in, n_head * d_k)\n",
        "        nn.init.normal_(gself.fc1_k.weight, mean=0, std=np.sqrt(2.0 / (d_k)))\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(temperature=np.power(d_k, 0.5))\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        d_k, d_in, n_head = self.d_k, self.d_in, self.n_head\n",
        "        sz_b, seq_len, _ = q.size()\n",
        "\n",
        "        q = torch.stack([self.Q for _ in range(sz_b)], dim=1).view(-1, d_k)  # (n*b) x d_k\n",
        "\n",
        "        k = self.fc1_k(v).view(sz_b, seq_len, n_head, d_k)\n",
        "        k = k.permute(2, 0, 1, 3).contiguous().view(-1, seq_len, d_k)  # (n*b) x lk x dk\n",
        "\n",
        "        v = torch.stack(v.split(v.shape[-1] // n_head, dim=-1)).view(n_head * sz_b, seq_len, -1)\n",
        "        output, attn = self.attention(q, k, v)\n",
        "        attn = attn.view(n_head, sz_b, 1, seq_len)\n",
        "        attn = attn.squeeze(dim=2)\n",
        "\n",
        "        output = output.view(n_head, sz_b, 1, d_in // n_head)\n",
        "        output = output.squeeze(dim=2)\n",
        "\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    ''' Scaled Dot-Product Attention '''\n",
        "\n",
        "    def __init__(self, temperature, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        attn = torch.matmul(q.unsqueeze(1), k.transpose(1, 2))\n",
        "        attn = attn / self.temperature\n",
        "\n",
        "        attn = self.softmax(attn)\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.matmul(attn, v)\n",
        "\n",
        "        return output, attn\n",
        "\n",
        "\n",
        "def get_sinusoid_encoding_table(positions, d_hid, T=1000):\n",
        "    ''' Sinusoid position encoding table\n",
        "    positions: int or list of integer, if int range(positions)'''\n",
        "\n",
        "    if isinstance(positions, int):\n",
        "        positions = list(range(positions))\n",
        "\n",
        "    def cal_angle(position, hid_idx):\n",
        "        return position / np.power(T, 2 * (hid_idx // 2) / d_hid)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, hid_j) for hid_j in range(d_hid)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in positions])\n",
        "\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.FloatTensor(sinusoid_table).cuda()\n",
        "    else:\n",
        "        return torch.FloatTensor(sinusoid_table)\n",
        "\n",
        "\n",
        "def get_sinusoid_encoding_table_var(positions, d_hid, clip=4, offset=3, T=1000):\n",
        "    ''' Sinusoid position encoding table\n",
        "    positions: int or list of integer, if int range(positions)'''\n",
        "\n",
        "    if isinstance(positions, int):\n",
        "        positions = list(range(positions))\n",
        "\n",
        "    x = np.array(positions)\n",
        "\n",
        "    def cal_angle(position, hid_idx):\n",
        "        return position / np.power(T, 2 * (hid_idx + offset // 2) / d_hid)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, hid_j) for hid_j in range(d_hid)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in positions])\n",
        "\n",
        "    sinusoid_table = np.sin(sinusoid_table)  # dim 2i\n",
        "    sinusoid_table[:, clip:] = torch.zeros(sinusoid_table[:, clip:].shape)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.FloatTensor(sinusoid_table).cuda()\n",
        "    else:\n",
        "        return torch.FloatTensor(sinusoid_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g9gkUFxbiqrp"
      },
      "outputs": [],
      "source": [
        "def get_decoder(n_neurons):\n",
        "    \"\"\"Returns an MLP with the layer widths specified in n_neurons.\n",
        "    Every linear layer but the last one is followed by BatchNorm + ReLu\n",
        "\n",
        "    args:\n",
        "        n_neurons (list): List of int that specifies the width and length of the MLP.\n",
        "    \"\"\"\n",
        "    layers = []\n",
        "    for i in range(len(n_neurons)-1):\n",
        "        layers.append(nn.Linear(n_neurons[i], n_neurons[i+1]))\n",
        "        if i < (len(n_neurons) - 2):\n",
        "            layers.extend([\n",
        "                nn.BatchNorm1d(n_neurons[i + 1]),\n",
        "                nn.ReLU()\n",
        "            ])\n",
        "    m = nn.Sequential(*layers)\n",
        "    return m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dBHl2Ov4h-dy"
      },
      "outputs": [],
      "source": [
        "def get_ntrainparams(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class PseLTae(nn.Module):\n",
        "    \"\"\"\n",
        "    Pixel-Set encoder + Lightweight Temporal Attention Encoder sequence classifier\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=10, mlp1=[10, 32, 64], pooling='mean_std', mlp2=[132, 128], with_extra=True,\n",
        "                 extra_size=4,\n",
        "                 n_head=16, d_k=8, d_model=256, mlp3=[256, 128], dropout=0.2, T=1000, len_max_seq=24, positions=None,\n",
        "                 mlp4=[128, 64, 32, 20], return_att=False):\n",
        "        super(PseLTae, self).__init__()\n",
        "        self.spatial_encoder = PixelSetEncoder(input_dim, mlp1=mlp1, pooling=pooling, mlp2=mlp2, with_extra=with_extra,\n",
        "                                               extra_size=extra_size)\n",
        "        self.temporal_encoder = LTAE(in_channels=mlp2[-1], n_head=n_head, d_k=d_k,\n",
        "                                           d_model=d_model, n_neurons=mlp3, dropout=dropout,\n",
        "                                           T=T, len_max_seq=len_max_seq, positions=positions, return_att=return_att\n",
        "                                           )\n",
        "        self.decoder = get_decoder(mlp4)\n",
        "        self.return_att = return_att\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "         Args:\n",
        "            input(tuple): (Pixel-Set, Pixel-Mask) or ((Pixel-Set, Pixel-Mask), Extra-features)\n",
        "            Pixel-Set : Batch_size x Sequence length x Channel x Number of pixels\n",
        "            Pixel-Mask : Batch_size x Sequence length x Number of pixels\n",
        "            Extra-features : Batch_size x Sequence length x Number of features\n",
        "        \"\"\"\n",
        "        out = self.spatial_encoder(input)\n",
        "        if self.return_att:\n",
        "            out, att = self.temporal_encoder(out)\n",
        "            out = self.decoder(out)\n",
        "            return out, att\n",
        "        else:\n",
        "            out = self.temporal_encoder(out)\n",
        "            out = self.decoder(out)\n",
        "            return out\n",
        "\n",
        "    def param_ratio(self):\n",
        "        total = get_ntrainparams(self)\n",
        "        s = get_ntrainparams(self.spatial_encoder)\n",
        "        t = get_ntrainparams(self.temporal_encoder)\n",
        "        c = get_ntrainparams(self.decoder)\n",
        "\n",
        "        print('TOTAL TRAINABLE PARAMETERS : {}'.format(total))\n",
        "        print('RATIOS: Spatial {:5.1f}% , Temporal {:5.1f}% , Classifier {:5.1f}%'.format(s / total * 100,\n",
        "                                                                                          t / total * 100,\n",
        "                                                                                          c / total * 100))\n",
        "\n",
        "        return total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3FB4twek7v0",
        "outputId": "7c3a4f8a-0a18-4a86-bba2-65afa1224b24"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "loaders = get_loaders(dt1, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKs2GSewb51P",
        "outputId": "e3fc1f00-c3f2-4f6a-871d-c1ee63998753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Fold 1\n",
            "Train 901, Val 301, Test 301\n",
            "128\n",
            "128\n",
            "Starting Fold 2\n",
            "Train 901, Val 301, Test 301\n",
            "128\n",
            "128\n",
            "Starting Fold 3\n",
            "Train 901, Val 301, Test 301\n",
            "128\n",
            "128\n",
            "Starting Fold 4\n",
            "Train 901, Val 301, Test 301\n",
            "128\n",
            "128\n",
            "Starting Fold 5\n",
            "Train 901, Val 301, Test 301\n",
            "128\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "for fold, (train_loader, val_loader, test_loader) in enumerate(loaders):\n",
        "  print('Starting Fold {}'.format(fold + 1))\n",
        "  print('Train {}, Val {}, Test {}'.format(len(train_loader), len(val_loader), len(test_loader)))\n",
        "\n",
        "  model_config = dict(input_dim=10, mlp1=[10,32,64], pooling='mean_std',\n",
        "                                  mlp2=[128, 132], n_head=16, d_k=8, mlp3=[256,128],\n",
        "                                  dropout=0.2, T=1000, len_max_seq=24,\n",
        "                                  positions=None,\n",
        "                                  mlp4=[128, 64, 32, 20], d_model=256)\n",
        "  model_config.update(with_extra=False, extra_size=None)\n",
        "  model = PseLTae(**model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f2-w0hRVg5iN"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "def weight_init(m):\n",
        "    '''\n",
        "    Initializes a model's parameters.\n",
        "    Credits to: https://gist.github.com/jeasinema\n",
        "\n",
        "    Usage:\n",
        "        model = Model()\n",
        "        model.apply(weight_init)\n",
        "    '''\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=0, std=1)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=0, std=1)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=0, std=1)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        try:\n",
        "            init.normal_(m.bias.data)\n",
        "        except AttributeError:\n",
        "            pass\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r-bpj1ldZrzE"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
        "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim() > 2:\n",
        "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1, input.size(2))  # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1, 1)\n",
        "\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1, target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = Variable(logpt.data.exp())\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type() != input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0, target.data.view(-1))\n",
        "            logpt = logpt * Variable(at)\n",
        "\n",
        "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
        "        if self.size_average:\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return loss.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4Q3Dp0DZcEXS"
      },
      "outputs": [],
      "source": [
        "def mIou(y_true, y_pred, n_classes):\n",
        "    \"\"\"\n",
        "    Mean Intersect over Union metric.\n",
        "    Computes the one versus all IoU for each class and returns the average.\n",
        "    Classes that do not appear in the provided set are not counted in the average.\n",
        "    Args:\n",
        "        y_true (1D-array): True labels\n",
        "        y_pred (1D-array): Predicted labels\n",
        "        n_classes (int): Total number of classes\n",
        "    Returns:\n",
        "        mean Iou (float)\n",
        "    \"\"\"\n",
        "    iou = 0\n",
        "    n_observed = n_classes\n",
        "    for i in range(n_classes):\n",
        "        y_t = (np.array(y_true) == i).astype(int)\n",
        "        y_p = (np.array(y_pred) == i).astype(int)\n",
        "\n",
        "        inter = np.sum(y_t * y_p)\n",
        "        union = np.sum((y_t + y_p > 0).astype(int))\n",
        "\n",
        "        if union == 0:\n",
        "            n_observed -= 1\n",
        "        else:\n",
        "            iou += inter / union\n",
        "\n",
        "    return iou / n_observed\n",
        "\n",
        "\n",
        "\n",
        "def confusion_matrix_analysis(mat):\n",
        "    \"\"\"\n",
        "    This method computes all the performance metrics from the confusion matrix. In addition to overall accuracy, the\n",
        "    precision, recall, f-score and IoU for each class is computed.\n",
        "    The class-wise metrics are averaged to provide overall indicators in two ways (MICRO and MACRO average)\n",
        "    Args:\n",
        "        mat (array): confusion matrix\n",
        "\n",
        "    Returns:\n",
        "        per_class (dict) : per class metrics\n",
        "        overall (dict): overall metrics\n",
        "\n",
        "    \"\"\"\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    per_class = {}\n",
        "\n",
        "    for j in range(mat.shape[0]):\n",
        "        d = {}\n",
        "        tp = np.sum(mat[j, j])\n",
        "        fp = np.sum(mat[:, j]) - tp\n",
        "        fn = np.sum(mat[j, :]) - tp\n",
        "\n",
        "        d['IoU'] = tp / (tp + fp + fn)\n",
        "        d['Precision'] = tp / (tp + fp)\n",
        "        d['Recall'] = tp / (tp + fn)\n",
        "        d['F1-score'] = 2 * tp / (2 * tp + fp + fn)\n",
        "\n",
        "        per_class[str(j)] = d\n",
        "\n",
        "        TP += tp\n",
        "        FP += fp\n",
        "        FN += fn\n",
        "\n",
        "    overall = {}\n",
        "    overall['micro_IoU'] = TP / (TP + FP + FN)\n",
        "    overall['micro_Precision'] = TP / (TP + FP)\n",
        "    overall['micro_Recall'] = TP / (TP + FN)\n",
        "    overall['micro_F1-score'] = 2 * TP / (2 * TP + FP + FN)\n",
        "\n",
        "    macro = pd.DataFrame(per_class).transpose().mean()\n",
        "    overall['MACRO_IoU'] = macro.loc['IoU']\n",
        "    overall['MACRO_Precision'] = macro.loc['Precision']\n",
        "    overall['MACRO_Recall'] = macro.loc['Recall']\n",
        "    overall['MACRO_F1-score'] = macro.loc['F1-score']\n",
        "\n",
        "    overall['Accuracy'] = np.sum(np.diag(mat)) / np.sum(mat)\n",
        "\n",
        "    return per_class, overall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LRouGtQ0nylH"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "model.apply(weight_init)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = FocalLoss(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BJHYtCTJpzLr"
      },
      "outputs": [],
      "source": [
        "import torchnet as tnt\n",
        "def recursive_todevice(x, device):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(device)\n",
        "    else:\n",
        "        return [recursive_todevice(c, device) for c in x]\n",
        "\n",
        "def evaluation(model, criterion, loader, device, mode='val'):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    acc_meter = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "    loss_meter = tnt.meter.AverageValueMeter()\n",
        "\n",
        "    for (x, y) in loader:\n",
        "        y_true.extend(list(map(int, y)))\n",
        "        x = recursive_todevice(x, device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = model(x)\n",
        "            loss = criterion(prediction, y)\n",
        "\n",
        "        acc_meter.add(prediction, y)\n",
        "        loss_meter.add(loss.item())\n",
        "\n",
        "        y_p = prediction.argmax(dim=1).cpu().numpy()\n",
        "        y_pred.extend(list(y_p))\n",
        "        # print(y_pred)\n",
        "        # print(y_true)\n",
        "\n",
        "    metrics = {'{}_accuracy'.format(mode): acc_meter.value()[0],\n",
        "               '{}_loss'.format(mode): loss_meter.value()[0],\n",
        "               '{}_IoU'.format(mode): mIou(y_true, y_pred, 20)}\n",
        "\n",
        "    if mode == 'val':\n",
        "        return metrics\n",
        "    # elif mode == 'test':\n",
        "    #     return metrics, confusion_matrix(y_true, y_pred, labels=list(range(config['num_classes'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcbNBBkUo7yb",
        "outputId": "bdd11c67-f3bb-4590-cf3b-562c628a3580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1/100\n",
            "Validation . . . \n",
            "Loss 3.2026,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 2/100\n",
            "Validation . . . \n",
            "Loss 3.2039,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 3/100\n",
            "Validation . . . \n",
            "Loss 3.2043,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 4/100\n",
            "Validation . . . \n",
            "Loss 3.2045,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 5/100\n",
            "Validation . . . \n",
            "Loss 3.2014,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 6/100\n",
            "Validation . . . \n",
            "Loss 3.2031,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 7/100\n",
            "Validation . . . \n",
            "Loss 3.2039,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 8/100\n",
            "Validation . . . \n",
            "Loss 3.2018,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 9/100\n",
            "Validation . . . \n",
            "Loss 3.2037,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 10/100\n",
            "Validation . . . \n",
            "Loss 3.2057,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 11/100\n",
            "Validation . . . \n",
            "Loss 3.2033,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 12/100\n",
            "Validation . . . \n",
            "Loss 3.2027,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 13/100\n",
            "Validation . . . \n",
            "Loss 3.2024,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 14/100\n",
            "Validation . . . \n",
            "Loss 3.2047,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 15/100\n",
            "Validation . . . \n",
            "Loss 3.2028,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 16/100\n",
            "Validation . . . \n",
            "Loss 3.2021,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 17/100\n",
            "Validation . . . \n",
            "Loss 3.2016,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 18/100\n",
            "Validation . . . \n",
            "Loss 3.2030,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 19/100\n",
            "Validation . . . \n",
            "Loss 3.2021,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 20/100\n",
            "Validation . . . \n",
            "Loss 3.2038,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 21/100\n",
            "Validation . . . \n",
            "Loss 3.2047,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 22/100\n",
            "Validation . . . \n",
            "Loss 3.2035,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 23/100\n",
            "Validation . . . \n",
            "Loss 3.2031,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 24/100\n",
            "Validation . . . \n",
            "Loss 3.2039,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 25/100\n",
            "Validation . . . \n",
            "Loss 3.2029,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 26/100\n",
            "Validation . . . \n",
            "Loss 3.2043,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 27/100\n",
            "Validation . . . \n",
            "Loss 3.2030,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 28/100\n",
            "Validation . . . \n",
            "Loss 3.2021,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 29/100\n",
            "Validation . . . \n",
            "Loss 3.2034,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 30/100\n",
            "Validation . . . \n",
            "Loss 3.2015,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 31/100\n",
            "Validation . . . \n",
            "Loss 3.2039,  Acc 0.03,  IoU 0.0000\n",
            "EPOCH 32/100\n",
            "Validation . . . \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation . . . \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 9\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m,  Acc \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m,  IoU \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     11\u001b[0m                                                                val_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_IoU\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# trainlog[epoch] = {**train_metrics, **val_metrics}\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# # checkpoint(fold + 1, trainlog, config)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# if val_metrics['val_IoU'] >= best_mIoU:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#             'optimizer': optimizer.state_dict()},\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#   os.path.join(config['res_dir'], 'Fold_{}'.format(fold + 1), 'model.pth.tar'))\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[14], line 15\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(model, criterion, loader, device, mode)\u001b[0m\n\u001b[1;32m     12\u001b[0m acc_meter \u001b[38;5;241m=\u001b[39m tnt\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mClassErrorMeter(accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m loss_meter \u001b[38;5;241m=\u001b[39m tnt\u001b[38;5;241m.\u001b[39mmeter\u001b[38;5;241m.\u001b[39mAverageValueMeter()\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y) \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     16\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, y)))\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m recursive_todevice(x, device)\n",
            "File \u001b[0;32m~/573/.project/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/573/.project/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1318\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1318\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shutdown_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m \n\u001b[1;32m   1323\u001b[0m \u001b[38;5;66;03m# Check if the next sample has already been generated\u001b[39;00m\n",
            "File \u001b[0;32m~/573/.project/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1443\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;66;03m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;66;03m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1443\u001b[0m     \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMP_STATUS_CHECK_INTERVAL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues:\n\u001b[1;32m   1445\u001b[0m     q\u001b[38;5;241m.\u001b[39mcancel_join_thread()\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentinel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainlog = {}\n",
        "best_mIoU = 0\n",
        "epochs = 100\n",
        "for epoch in range(1, epochs + 1):\n",
        "  print('EPOCH {}/{}'.format(epoch, epochs))\n",
        "  model.train()\n",
        "  print('Validation . . . ')\n",
        "  model.eval()\n",
        "  val_metrics = evaluation(model, criterion, val_loader, device=device, mode='val')\n",
        "  print('Loss {:.4f},  Acc {:.2f},  IoU {:.4f}'.format(val_metrics['val_loss'], val_metrics['val_accuracy'],\n",
        "                                                                 val_metrics['val_IoU']))\n",
        "  # trainlog[epoch] = {**train_metrics, **val_metrics}\n",
        "  # # checkpoint(fold + 1, trainlog, config)\n",
        "  # if val_metrics['val_IoU'] >= best_mIoU:\n",
        "  #   best_mIoU = val_metrics['val_IoU']\n",
        "  #   torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
        "  #             'optimizer': optimizer.state_dict()},\n",
        "  #   os.path.join(config['res_dir'], 'Fold_{}'.format(fold + 1), 'model.pth.tar'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNAD2lXo75NR",
        "outputId": "96631868-4492-42f4-8acf-bdf3d9454b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "# dttest[0]\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azBPngTKxHHC",
        "outputId": "37f7215e-6106-45d3-ae2a-b0d987cf2fbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "dl = data.DataLoader(dttest, batch_size=128, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY2AzOOVyFHA",
        "outputId": "6be31b51-e4b0-4c58-92be-4e30e28de243"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for (x, y) in tqdm(dl):\n",
        "  ids = list(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RcOTGMW7IN3",
        "outputId": "29788707-0782-43f8-c72e-6b00daa82467"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 24, 10, 64])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTeZNaZIwyMW"
      },
      "outputs": [],
      "source": [
        "def recursive_todevice(x, device):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.to(  device)\n",
        "    else:\n",
        "        return [recursive_todevice(c, device) for c in x]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlyqHJltxjtg"
      },
      "outputs": [],
      "source": [
        "x = recursive_todevice(x, device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02yz4f0q7RTH",
        "outputId": "451b592e-51bf-4f9d-be11-c903094a498a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 24, 10, 64])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKIzDj637eA2",
        "outputId": "f5fb3a5a-75c5-4f91-c673-d5609655be69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tST8alYxrG_"
      },
      "outputs": [],
      "source": [
        "pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mwF25a12NcN",
        "outputId": "17143f3e-4dd7-4211-b5f3-554aa0008544"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.2368, -1.9760, -0.3465, -3.9236,  0.9039,  0.4160, -2.4715,  2.4870,\n",
              "          1.1034, -0.9424,  0.9144,  1.6674, -0.9879, -0.8016,  3.0061, -1.5765,\n",
              "          1.8263, -0.2311, -2.0076, -1.4873]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# x[0].shape\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Iqx2JzghnE",
        "outputId": "ed5a1ff6-a798-4ead-e836-57b9b224d6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "# # prompt: read png file as flattened numpy array\n",
        "\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "\n",
        "# # Open the PNG image\n",
        "# image = Image.open('./new/2024-02-08-00:00_2024-02-08-23:59_Sentinel-2_L2A_B01_(Raw).png')\n",
        "\n",
        "# # Convert the image to a numpy array\n",
        "# image_array = np.asarray(image)\n",
        "\n",
        "# # Flatten the numpy array\n",
        "# flattened_array = image_array.flatten()\n",
        "\n",
        "# # Print the flattened numpy array\n",
        "# print(flattened_array)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd7wPgzHj54H"
      },
      "outputs": [],
      "source": [
        "# prompt: read all files in a directory as numpy array\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "def read_all_npy_as_array(directory):\n",
        "  \"\"\"\n",
        "  Reads all files in a directory as numpy arrays and returns a single array containing all the data.\n",
        "\n",
        "  Args:\n",
        "    directory (str): The directory containing the numpy files.\n",
        "\n",
        "  Returns:\n",
        "    np.ndarray: A single numpy array containing all the data from the files in the directory.\n",
        "  \"\"\"\n",
        "\n",
        "  # Get a list of all the files in the directory\n",
        "  files = os.listdir(directory)\n",
        "\n",
        "  # Initialize an empty list to store the data from each file\n",
        "  data = []\n",
        "\n",
        "  # Loop through the files and read them as numpy arrays\n",
        "  for file in files:\n",
        "    file_path = os.path.join(directory, file)\n",
        "    if len(data)>0:\n",
        "      image = Image.open(file_path)\n",
        "      datatem = np.asarray(image)\n",
        "      datatem = datatem.flatten()\n",
        "      data = np.add(data, datatem)\n",
        "    else:\n",
        "      image = Image.open(file_path)\n",
        "      data = np.asarray(image)\n",
        "      data = data.flatten()\n",
        "\n",
        "  # Concatenate the data from all the files into a single array\n",
        "  # data = np.concatenate(data, axis=0)\n",
        "\n",
        "  return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nXJfWxtkMsH",
        "outputId": "72b5cf0a-e252-4745-af9a-11244d35bbe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(24, 10, 304)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = np.load('./drive/MyDrive/PixelSet-TOY/DATA/101.npy')\n",
        "t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2CH64h5oZDX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import pickle as pkl\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "class PixelSetDataTest(data.Dataset):\n",
        "    def __init__(self, data, npixel):\n",
        "        \"\"\"\n",
        "\n",
        "        Args:\n",
        "            folder (str): path to the main folder of the dataset, formatted as indicated in the readme\n",
        "            labels (str): name of the nomenclature to use in the labels.json file\n",
        "            npixel (int): Number of sampled pixels in each parcel\n",
        "            sub_classes (list): If provided, only the samples from the given list of classes are considered.\n",
        "            (Can be used to remove classes with too few samples)\n",
        "            norm (tuple): (mean,std) tuple to use for normalization\n",
        "            extra_feature (str): name of the additional static feature file to use\n",
        "            jitter (tuple): if provided (sigma, clip) values for the addition random gaussian noise\n",
        "            return_id (bool): if True, the id of the yielded item is also returned (useful for inference)\n",
        "        \"\"\"\n",
        "        super(PixelSetDataTest, self).__init__()\n",
        "\n",
        "        # self.folder = folder\n",
        "        # self.data_folder = os.path.join(folder, 'DATA')\n",
        "        # self.meta_folder = os.path.join(folder, 'META')\n",
        "        # self.labels = labels\n",
        "        self.data = data\n",
        "        self.npixel = npixel\n",
        "        # self.norm = norm\n",
        "\n",
        "        # self.extra_feature = extra_feature\n",
        "        # self.jitter = jitter  # (sigma , clip )\n",
        "        # self.return_id = return_id\n",
        "\n",
        "        # l = [f for f in os.listdir(self.data_folder) if f.endswith('.npy')]\n",
        "        # self.pid = [int(f.split('.')[0]) for f in l]\n",
        "        # self.pid = list(np.sort(self.pid))\n",
        "\n",
        "        # self.pid = list(map(str, self.pid))\n",
        "        # self.len = len(self.pid)\n",
        "\n",
        "        # with open(os.path.join(folder, 'META', 'dates.json'), 'r') as file:\n",
        "        #     d = json.loads(file.read())\n",
        "        # self.dates = [d[str(i)] for i in range(len(d))]\n",
        "        # self.date_positions = date_positions(self.dates)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        Returns a Pixel-Set sequence tensor with its pixel mask and optional additional features.\n",
        "        For each item npixel pixels are randomly dranw from the available pixels.\n",
        "        If the total number of pixel is too small one arbitrary pixel is repeated. The pixel mask keeps track of true\n",
        "        and repeated pixels.\n",
        "        Returns:\n",
        "              (Pixel-Set, Pixel-Mask) or ((Pixel-Set, Pixel-Mask), Extra-features) with:\n",
        "                Pixel-Set: Sequence_length x Channels x npixel\n",
        "                Pixel-Mask : Sequence_length x npixel\n",
        "                Extra-features : Sequence_length x Number of additional features\n",
        "\n",
        "        \"\"\"\n",
        "        # x0 = np.load(os.path.join(self.folder, 'DATA', '{}.npy'.format(self.pid[item])))\n",
        "        x0 = self.data\n",
        "        # if len(self.target) > 0:\n",
        "        #   y = self.target[item]\n",
        "        # else:\n",
        "        #   y = []\n",
        "\n",
        "        if x0.shape[-1] > self.npixel:\n",
        "            idx = np.random.choice(list(range(x0.shape[-1])), size=self.npixel, replace=False)\n",
        "            x = x0[:, :, idx]\n",
        "            mask = np.ones(self.npixel)\n",
        "\n",
        "        elif x0.shape[-1] < self.npixel:\n",
        "\n",
        "            if x0.shape[-1] == 0:\n",
        "                x = np.zeros((*x0.shape[:2], self.npixel))\n",
        "                mask = np.zeros(self.npixel)\n",
        "                mask[0] = 1\n",
        "            else:\n",
        "                x = np.zeros((*x0.shape[:2], self.npixel))\n",
        "                x[:, :, :x0.shape[-1]] = x0\n",
        "                x[:, :, x0.shape[-1]:] = np.stack([x[:, :, 0] for _ in range(x0.shape[-1], x.shape[-1])], axis=-1)\n",
        "                mask = np.array(\n",
        "                    [1 for _ in range(x0.shape[-1])] + [0 for _ in range(x0.shape[-1], self.npixel)])\n",
        "        else:\n",
        "            x = x0\n",
        "            mask = np.ones(self.npixel)\n",
        "\n",
        "        x = x.astype('float')\n",
        "\n",
        "\n",
        "        mask = np.stack([mask for _ in range(x.shape[0])], axis=0)  # Add temporal dimension to mask\n",
        "        data = (Tensor(x), Tensor(mask))\n",
        "        return data, torch.from_numpy(np.array(y, dtype=int))\n",
        "\n",
        "\n",
        "class PixelSetData_preloadedTest(PixelSetDataTest):\n",
        "    \"\"\" Wrapper class to load all the dataset to RAM at initialization (when the hardware permits it).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, npixel):\n",
        "        super(PixelSetData_preloadedTest, self).__init__(data, npixel)\n",
        "        self.samples = []\n",
        "        print('Loading samples to memory . . .')\n",
        "        for item in range(len(self)):\n",
        "            self.samples.append(super(PixelSetData_preloadedTest, self).__getitem__(item))\n",
        "        print('Done !')\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.samples[item]\n",
        "\n",
        "\n",
        "def parse(date):\n",
        "    d = str(date)\n",
        "    return int(d[:4]), int(d[4:6]), int(d[6:])\n",
        "\n",
        "\n",
        "def interval_days(date1, date2):\n",
        "    return abs((dt.datetime(*parse(date1)) - dt.datetime(*parse(date2))).days)\n",
        "\n",
        "\n",
        "def date_positions(dates):\n",
        "    pos = []\n",
        "    for d in dates:\n",
        "        pos.append(interval_days(d, dates[0]))\n",
        "    return pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "4QjlC566rZOI",
        "outputId": "236f3ce0-eaef-4306-9459-600248a4282f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './new/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-29c41ac4b7a8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_all_npy_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./new/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-aedbff881502>\u001b[0m in \u001b[0;36mread_all_npy_as_array\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Get a list of all the files in the directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Initialize an empty list to store the data from each file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './new/'"
          ]
        }
      ],
      "source": [
        "data2 = read_all_npy_as_array(\"./new/\");\n",
        "data2 = np.expand_dims(data2, axis=0)\n",
        "data2 = np.expand_dims(data2, axis=0)\n",
        "data2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfLq1Hb5zgS",
        "outputId": "c3a9b2de-fbd1-473a-c90c-be564698c913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading samples to memory . . .\n",
            "Done !\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.PixelSetData_preloadedTest at 0x7e3f3dae0c40>"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mean_std = pkl.load(open('./drive/MyDrive/PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "dttest2 = PixelSetData_preloadedTest(data = data2, npixel=64)\n",
        "dttest2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap7bIEaH52m6",
        "outputId": "a8dc05a8-e3de-4f63-ebec-321d73f7c007"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "dl2 = data.DataLoader(dttest2, batch_size=128, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfXddIK9557H",
        "outputId": "20124879-937c-4574-9f8f-d29b57158c7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for (x2, y) in tqdm(dttest2):\n",
        "  ids = list(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQi7bXiM5-n0",
        "outputId": "bc2f1e01-7572-458d-acf8-445fbc50dd48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 64])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x2[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "e4MObY5YQ-7m",
        "outputId": "f012f61f-b300-404c-cd2d-97723e3361b6"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'x2' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0a15ae6e864e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x2' is not defined"
          ]
        }
      ],
      "source": [
        "model(x2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBUJPTW34h_o"
      },
      "outputs": [],
      "source": [
        "data1 = np.load(\"./test/DATA/2.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbOdrNV24vhf",
        "outputId": "7811a7c8-8476-4aa9-8e5e-317dcb3da76e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 10, 576)"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHD360O8o9C9",
        "outputId": "605e73da-fde2-4aa7-e9f0-5b162b2c3c0f"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './drive/MyDrive/PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mean_std \u001b[38;5;241m=\u001b[39m pkl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./drive/MyDrive/PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      2\u001b[0m dttest1 \u001b[38;5;241m=\u001b[39m PixelSetData_preloadedTest(data \u001b[38;5;241m=\u001b[39m data1, npixel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
            "File \u001b[0;32m~/573/.project/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './drive/MyDrive/PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl'"
          ]
        }
      ],
      "source": [
        "mean_std = pkl.load(open('./drive/MyDrive/PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "dttest1 = PixelSetData_preloadedTest(data = data1, npixel=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj2gt8h9UCol",
        "outputId": "a14fcb8d-a46a-4047-91bb-f95b7d076c04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading samples to memory . . .\n",
            "Done !\n"
          ]
        }
      ],
      "source": [
        "subset = [1, 3, 4, 5, 6, 8, 9, 12, 13, 14, 16, 18, 19, 23, 28, 31, 33, 34, 36, 39]\n",
        "mean_std = pkl.load(open('./drive/MyDrive/PixelSet-TOY/S2-2017-T31TFM-meanstd.pkl', 'rb'))\n",
        "dttest = PixelSetData_preloaded('./test/', labels='label_19class', npixel=64,\n",
        "                                    sub_classes=None,\n",
        "                                    norm=mean_std,\n",
        "                                    extra_feature=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-86SUXXroMM",
        "outputId": "1ca8a224-126a-4dcf-c131-2cccd01685c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "dl = data.DataLoader(dttest, batch_size=128, num_workers=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYlFbYpN5hDO",
        "outputId": "96539744-934c-4ce2-a951-ef3979da95f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dl.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1eGPzt3sJtV",
        "outputId": "5a7105f9-8f1d-4d77-aab9-7b548c41eb8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.38it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for (x, y) in tqdm(dl):\n",
        "  ids = list(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Deq3vYnpsLUP"
      },
      "outputs": [],
      "source": [
        "x = recursive_todevice(x, device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4dCnoq-5abv",
        "outputId": "7f855c5d-f46b-4b36-d56b-ee0274fd97c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 24, 10, 64])"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dm5hoJlsRqi",
        "outputId": "e49ff30e-17e5-4e38-e42c-b7b2abdea06b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2.6035, -1.6439,  0.5844, -0.6367, -0.8194, -0.7185, -0.2194, -0.0597,\n",
              "          0.0922, -0.4818, -2.1169,  2.0929, -1.0708,  1.7885,  1.0255,  1.4232,\n",
              "          1.2237, -0.6139,  3.0601, -3.1487]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW_jBGVDtSc8"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), './model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKRCn_C1tk6z",
        "outputId": "327b4d51-c5d8-457b-eec3-567750f46ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "model_config = dict(input_dim=10, mlp1=[10,32,64], pooling='mean_std',\n",
        "                                  mlp2=[128, 132], n_head=16, d_k=8, mlp3=[256,128],\n",
        "                                  dropout=0.2, T=1000, len_max_seq=24,\n",
        "                                  positions=None,\n",
        "                                  mlp4=[128, 64, 32, 20], d_model=256)\n",
        "model_config.update(with_extra=False, extra_size=None)\n",
        "model2 = PseLTae(**model_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LbMHgaotpb_"
      },
      "outputs": [],
      "source": [
        "torch.save(model, './model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peo1OshEtzDn"
      },
      "outputs": [],
      "source": [
        "model2 = torch.load('./model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Uo4BC4uSum",
        "outputId": "8dc626e2-ce48-4152-a608-8cdb5326d27d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2.6035, -1.6439,  0.5844, -0.6367, -0.8194, -0.7185, -0.2194, -0.0597,\n",
              "          0.0922, -0.4818, -2.1169,  2.0929, -1.0708,  1.7885,  1.0255,  1.4232,\n",
              "          1.2237, -0.6139,  3.0601, -3.1487]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViLKmS0muaot",
        "outputId": "923eb5c3-03d3-45c3-edd7-0b588fab3d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8DqmXqY8mBx",
        "outputId": "d05f01ef-6b53-41df-da19-5c790db9f806"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjNfXWtm9Kdz",
        "outputId": "63c22e7d-83aa-4dfe-9f15-dd60a31b5fad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[[[ 0.9341, -0.9725,  0.9455,  ...,  0.9377,  0.9337,  0.9225],\n",
              "           [ 0.8859, -0.9780,  0.9612,  ...,  0.9813,  0.9585,  0.9617],\n",
              "           [ 1.1415, -0.9614,  1.2673,  ...,  1.2588,  1.2873,  1.2687],\n",
              "           ...,\n",
              "           [ 0.3158, -0.9757,  0.2982,  ...,  0.2956,  0.2999,  0.3034],\n",
              "           [ 1.1350, -0.9894,  1.1331,  ...,  1.1316,  1.1272,  1.1398],\n",
              "           [ 2.4030, -0.9733,  2.3993,  ...,  2.4090,  2.4070,  2.3928]],\n",
              " \n",
              "          [[ 0.8983, -0.9902,  0.8961,  ...,  0.8879,  0.9018,  0.8858],\n",
              "           [ 0.8302, -0.9688,  0.9245,  ...,  0.9165,  0.9294,  0.9309],\n",
              "           [ 1.1136, -0.9618,  1.2183,  ...,  1.2334,  1.2090,  1.2340],\n",
              "           ...,\n",
              "           [ 0.3463, -0.9917,  0.3030,  ...,  0.2919,  0.3020,  0.3030],\n",
              "           [ 1.1303, -0.9776,  1.1334,  ...,  1.1414,  1.1361,  1.1202],\n",
              "           [ 2.4052, -0.9900,  2.4019,  ...,  2.4025,  2.4092,  2.4056]],\n",
              " \n",
              "          [[ 0.8578, -0.9700,  0.8597,  ...,  0.8519,  0.8558,  0.8588],\n",
              "           [ 0.7691, -0.9907,  0.8560,  ...,  0.8560,  0.8469,  0.8705],\n",
              "           [ 1.0339, -0.9788,  1.1738,  ...,  1.1510,  1.1578,  1.1672],\n",
              "           ...,\n",
              "           [ 0.2945, -1.0045,  0.2474,  ...,  0.2539,  0.2464,  0.2636],\n",
              "           [ 1.0814, -0.9856,  1.0665,  ...,  1.0845,  1.0527,  1.0916],\n",
              "           [ 2.3587, -1.0003,  2.3549,  ...,  2.3660,  2.3481,  2.3512]],\n",
              " \n",
              "          ...,\n",
              " \n",
              "          [[ 3.6371, -0.9932,  3.6272,  ...,  3.6340,  3.6306,  3.6408],\n",
              "           [ 1.8148, -1.0219,  1.9391,  ...,  1.9460,  1.9407,  1.9467],\n",
              "           [ 2.7703, -0.9858,  2.9735,  ...,  2.9778,  2.9920,  2.9693],\n",
              "           ...,\n",
              "           [ 0.1555, -0.9967,  0.1194,  ...,  0.1327,  0.1252,  0.1227],\n",
              "           [ 0.8624, -1.0062,  0.8712,  ...,  0.8801,  0.8693,  0.8634],\n",
              "           [ 2.5059, -0.9841,  2.5083,  ...,  2.5156,  2.4889,  2.5206]],\n",
              " \n",
              "          [[ 3.4517, -0.9908,  3.4434,  ...,  3.4609,  3.4482,  3.4296],\n",
              "           [ 1.7399, -0.9815,  1.8633,  ...,  1.8830,  1.8847,  1.8641],\n",
              "           [ 2.6160, -0.9712,  2.8313,  ...,  2.8077,  2.8440,  2.8239],\n",
              "           ...,\n",
              "           [ 0.1273, -0.9927,  0.0824,  ...,  0.1054,  0.1159,  0.1096],\n",
              "           [ 0.8385, -0.9794,  0.8271,  ...,  0.8294,  0.8243,  0.8297],\n",
              "           [ 2.3817, -0.9836,  2.3697,  ...,  2.3763,  2.3607,  2.3744]],\n",
              " \n",
              "          [[ 3.1679, -0.9814,  3.1930,  ...,  3.1954,  3.1736,  3.1807],\n",
              "           [ 1.6333, -0.9882,  1.7509,  ...,  1.7479,  1.7698,  1.7656],\n",
              "           [ 2.3773, -0.9686,  2.5653,  ...,  2.5519,  2.5700,  2.5690],\n",
              "           ...,\n",
              "           [ 0.1226, -0.9965,  0.0892,  ...,  0.1124,  0.1194,  0.1096],\n",
              "           [ 0.7653, -0.9997,  0.7642,  ...,  0.7646,  0.7629,  0.7693],\n",
              "           [ 2.1717, -0.9868,  2.1677,  ...,  2.1651,  2.1776,  2.1583]]]]),\n",
              " tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]]])]"
            ]
          },
          "execution_count": 199,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
